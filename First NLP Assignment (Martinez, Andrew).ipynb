{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label   X1   X2  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  NaN  NaN  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  NaN  NaN  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  NaN  NaN  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  NaN  NaN  \n",
       "4  It's primary day in New York and front-runners...  REAL  NaN  NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "raw_train_df = pd.read_csv('fake_or_real_news_training.csv')\n",
    "raw_test_df = pd.read_csv('fake_or_real_news_test.csv')\n",
    "\n",
    "raw_train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2321, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10498</td>\n",
       "      <td>September New Homes Sales Rise——-Back To 1992 ...</td>\n",
       "      <td>September New Homes Sales Rise Back To 1992 Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2439</td>\n",
       "      <td>Why The Obamacare Doomsday Cult Can't Admit It...</td>\n",
       "      <td>But when Congress debated and passed the Patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>864</td>\n",
       "      <td>Sanders, Cruz resist pressure after NY losses,...</td>\n",
       "      <td>The Bernie Sanders and Ted Cruz campaigns vowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4128</td>\n",
       "      <td>Surviving escaped prisoner likely fatigued and...</td>\n",
       "      <td>Police searching for the second of two escaped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>662</td>\n",
       "      <td>Clinton and Sanders neck and neck in Californi...</td>\n",
       "      <td>No matter who wins California's 475 delegates ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0  10498  September New Homes Sales Rise——-Back To 1992 ...   \n",
       "1   2439  Why The Obamacare Doomsday Cult Can't Admit It...   \n",
       "2    864  Sanders, Cruz resist pressure after NY losses,...   \n",
       "3   4128  Surviving escaped prisoner likely fatigued and...   \n",
       "4    662  Clinton and Sanders neck and neck in Californi...   \n",
       "\n",
       "                                                text  \n",
       "0  September New Homes Sales Rise Back To 1992 Le...  \n",
       "1  But when Congress debated and passed the Patie...  \n",
       "2  The Bernie Sanders and Ted Cruz campaigns vowe...  \n",
       "3  Police searching for the second of two escaped...  \n",
       "4  No matter who wins California's 475 delegates ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train_df = raw_train_df.copy()\n",
    "prepared_test_df = raw_test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10498</td>\n",
       "      <td>September New Homes Sales Rise——-Back To 1992 ...</td>\n",
       "      <td>September New Homes Sales Rise Back To 1992 Le...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2439</td>\n",
       "      <td>Why The Obamacare Doomsday Cult Can't Admit It...</td>\n",
       "      <td>But when Congress debated and passed the Patie...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>864</td>\n",
       "      <td>Sanders, Cruz resist pressure after NY losses,...</td>\n",
       "      <td>The Bernie Sanders and Ted Cruz campaigns vowe...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4128</td>\n",
       "      <td>Surviving escaped prisoner likely fatigued and...</td>\n",
       "      <td>Police searching for the second of two escaped...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>662</td>\n",
       "      <td>Clinton and Sanders neck and neck in Californi...</td>\n",
       "      <td>No matter who wins California's 475 delegates ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0  10498  September New Homes Sales Rise——-Back To 1992 ...   \n",
       "1   2439  Why The Obamacare Doomsday Cult Can't Admit It...   \n",
       "2    864  Sanders, Cruz resist pressure after NY losses,...   \n",
       "3   4128  Surviving escaped prisoner likely fatigued and...   \n",
       "4    662  Clinton and Sanders neck and neck in Californi...   \n",
       "\n",
       "                                                text label  \n",
       "0  September New Homes Sales Rise Back To 1992 Le...  None  \n",
       "1  But when Congress debated and passed the Patie...  None  \n",
       "2  The Bernie Sanders and Ted Cruz campaigns vowe...  None  \n",
       "3  Police searching for the second of two escaped...  None  \n",
       "4  No matter who wins California's 475 delegates ...  None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_test_df['label'] = None\n",
    "prepared_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(df, model, vectorizer, dependent_var, size, seed, return_model=True):\n",
    "    df_new = df.copy()\n",
    "\n",
    "    X = df_new.loc[:, 'text']\n",
    "    y = df_new.loc[:, dependent_var]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=size, random_state=seed)\n",
    "\n",
    "    pipeline = make_pipeline(vectorizer, model).fit(X=X_train, y=y_train)\n",
    "    pred = pipeline.predict(X_test)\n",
    "\n",
    "    if return_model == False:\n",
    "        return(pipeline.score(X_test, y_test), y_test, pred)\n",
    "    else:\n",
    "        return(pipeline.score(X_test, y_test), y_test, pred, pipeline)\n",
    "\n",
    "\n",
    "def cv_evaluate(df, model, vectorizer, target_var, seed, cv, standalone=False, metric='accuracy'):\n",
    "    df_new = df.copy()\n",
    "    kfolds = KFold(n_splits=cv, shuffle=True, random_state=seed)\n",
    "\n",
    "    X = df_new.loc[:, 'text']\n",
    "    y = df_new.loc[:, target_var]\n",
    "\n",
    "    if standalone == True:\n",
    "        benchmark_model = make_pipeline(\n",
    "            vectorizer, model).fit(X=X, y=y.values.ravel())\n",
    "    else:\n",
    "        benchmark_model = make_pipeline(model).fit(X=X, y=y.values.ravel())\n",
    "        \n",
    "    scores = cross_val_score(benchmark_model, X, y.values.ravel(),\n",
    "                             scoring=metric, cv=kfolds)\n",
    "    return scores[scores >= 0.0]\n",
    "\n",
    "\n",
    "def confusion_heat_map(test_set, prediction_set, class_names):\n",
    "    cm = confusion_matrix(test_set, prediction_set, class_names)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # create heatmap\n",
    "    g = sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt='g',\n",
    "                    xticklabels=True, yticklabels=True)\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_yticklabels(class_names)\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def run_full_iteration(df, model, vectorizer, target_var, size, seed, cv=5):\n",
    "    score, y_test, pred, model = score_model(\n",
    "        df, model, vectorizer, target_var, size, seed)\n",
    "    print(\"Accuracy: %0.3f\" % score)\n",
    "\n",
    "    accuracy = cv_evaluate(df, model, vectorizer, target_var, seed, cv)\n",
    "    print('Mean Accuracy after CV: {:.3f} +/- {:.03f}'.format(np.mean(accuracy), np.std(accuracy)))\n",
    "    print('Best Accuracy after CV: {:.3f}'.format(max(accuracy)))\n",
    "\n",
    "    confusion_heat_map(y_test, pred, ['FAKE', 'REAL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB: 0.809707 (0.026723)\n",
      "LR: 0.906729 (0.005771)\n",
      "RFC: 0.831965 (0.016928)\n",
      "SVM: 0.916733 (0.008318)\n"
     ]
    }
   ],
   "source": [
    "# Set test set size, seed and target metric for the rest of the pipeline\n",
    "size = 0.20\n",
    "seed = 12345\n",
    "target_var = 'label'\n",
    "\n",
    "models = []\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', multi_class='auto')))\n",
    "# models.append(('KNN', KNeighborsClassifier())) #very poor performance\n",
    "models.append(('RFC', RandomForestClassifier(random_state = seed)))\n",
    "models.append(('SVM', SVC(kernel='linear')))\n",
    "# models.append(('GB', GradientBoostingClassifier())) #takes too long\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    cv_results = cv_evaluate(prepared_train_df, model,\n",
    "                             vectorizer, target_var, seed, cv=4, standalone=True)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB: 0.876972 (0.010760)\n",
      "RFC: 0.833461 (0.012953)\n",
      "SVM: 0.816958 (0.017469)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "models = []\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "# models.append(('LR', LogisticRegression(solver='lbfgs', multi_class='auto'))) #Fails to converge\n",
    "# models.append(('KNN', KNeighborsClassifier())) #very poor performance\n",
    "models.append(('RFC', RandomForestClassifier(random_state = seed)))\n",
    "models.append(('SVM', SVC(kernel='linear')))\n",
    "# models.append(('GB', GradientBoostingClassifier())) #takes too long\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    cv_results = cv_evaluate(prepared_train_df, model,\n",
    "                             vectorizer, target_var, seed, cv=4, standalone=True)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.907\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "run_full_iteration(prepared_train_df, model, vectorizer, target_var, size, seed, cv=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE1: Combine Title and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe1_train_df = prepared_train_df.copy()\n",
    "fe1_test_df = fe1_test_df.copy()\n",
    "\n",
    "fe1_train_df['combined'] = fe1_train_df['title'] + fe1_train_df['text']\n",
    "fe1_test_df['combined'] = fe1_test_df['title'] + fe1_test_df['text']\n",
    "fe1_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "run_full_iteration(prepared_train_df, model, vectorizer, target_var, size, seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
